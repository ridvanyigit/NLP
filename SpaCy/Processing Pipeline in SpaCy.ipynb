{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPlQSzv890vBpsT+SJUKx1o"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Processing Text\n","When you call nlp on a text, spaCy will tokenize it and then call each component on the Doc, in order. It then returns the processed Doc that you can work with."],"metadata":{"id":"IyN3ZFA4xF12"}},{"cell_type":"code","execution_count":95,"metadata":{"id":"po889FHjvWet","executionInfo":{"status":"ok","timestamp":1741008657008,"user_tz":-60,"elapsed":7,"user":{"displayName":"Ridvan Yigit","userId":"01752453935051821250"}}},"outputs":[],"source":["# Importing Necessary Libraries and Filtering Warnings\n","import spacy\n","from spacy.matcher import Matcher\n","from spacy.tokens import Span\n","from spacy import displacy\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"spacy.pipeline.lemmatizer\")"]},{"cell_type":"code","source":["# Processing a Simple Text\n","nlp = spacy.load('en_core_web_sm')\n","doc = nlp(\"This is raw text\")\n","print(doc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KrA2k5LeLBNt","executionInfo":{"status":"ok","timestamp":1741008657912,"user_tz":-60,"elapsed":892,"user":{"displayName":"Ridvan Yigit","userId":"01752453935051821250"}},"outputId":"02741b98-5fba-42ff-dee3-a82a87c0db1b"},"execution_count":96,"outputs":[{"output_type":"stream","name":"stdout","text":["This is raw text\n"]}]},{"cell_type":"markdown","source":["When processing large volumes of text, the statistical models are usually more efficient if you let them work on batches of texts. SpaCy's nlp.pipe method takes an iterable of text and yields processed Doc objects. The batching is done internally."],"metadata":{"id":"2VSkcFAT5dmC"}},{"cell_type":"code","source":["# Processing Multiple Texts (nlp.pipe)\n","texts = [\"This is raw text\", \"There is lots of text\"]\n","doc = list(nlp.pipe(texts))\n","print(doc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WQI_ECsTLK0g","executionInfo":{"status":"ok","timestamp":1741008657912,"user_tz":-60,"elapsed":5,"user":{"displayName":"Ridvan Yigit","userId":"01752453935051821250"}},"outputId":"13834f64-e1ca-49e0-a414-99ea14801eec"},"execution_count":97,"outputs":[{"output_type":"stream","name":"stdout","text":["[This is raw text, There is lots of text]\n"]}]},{"cell_type":"markdown","source":["> Tips for efficient processing\n","\n","*   Process the texts as stream using nlp.pipe and buffer them in batches, instead of by-one-by. This is usually much more efficient.\n","*   Only apply the pipline components you need. Getting prediction from the model that you don't actually need adds up and becomes very efficient at scale. To prevent this, use the disable keyword argument to disable components you don't need.\n","\n","> In this example, we're using `nlp.pipe`to process a (potentially very large) iterable of texts as a stream. Because we're only accessing the named entities in `doc.ents` (set by the ner component), we'll disable all other statistical components (the tagger and parser) during processing. nlp.pipe yields Doc objects, so we can iterable over them and access the named entity predictions:"],"metadata":{"id":"at0GY1rx6vJd"}},{"cell_type":"code","source":["# Disabling NER (inside pipe)\n","texts = [\n","    \"Net income was $9.4 million compared to the prior year of $2.7 million \",\n","    \"Revenue exceeded twelve billion dollars, with a loss of $1b.\"\n","    ]\n","\n","nlp = spacy.load(\"en_core_web_sm\")\n","docs = list(nlp.pipe(texts, disable=[\"tagger\", \"parser\"]))\n","\n","for doc in docs:\n","    # Do something with the doc here\n","    print([(ent.text, ent.label_) for ent in doc.ents])\n","    print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j1fMWNXVLV2D","executionInfo":{"status":"ok","timestamp":1741008658557,"user_tz":-60,"elapsed":646,"user":{"displayName":"Ridvan Yigit","userId":"01752453935051821250"}},"outputId":"26b43833-4f20-423c-b798-3dcdda1129b7"},"execution_count":98,"outputs":[{"output_type":"stream","name":"stdout","text":["[('$9.4 million', 'MONEY'), ('the prior year', 'DATE'), ('$2.7 million', 'MONEY')]\n","\n","[('twelve billion dollars', 'MONEY'), ('1b', 'MONEY')]\n","\n"]}]},{"cell_type":"markdown","source":["## How `Pipelines` Work\n","SpaCy makes it very easy to create your own pipelines consisting of reusable components - this includes spaCy's default tagger, parser and entity recognizer, but also your own custom processing functions. A pipeline component can be added to an already existing nlp objects, specified when initializing a Language class, or defined within a model package.\n","\n","When you load a model, spaCy first consults the model's meta.json.\n","\n","The meta typically includes the model details, the ID of a Language class, and a optional list of pipeline components.SpaCy then does the following:\n","\n","\n","*   Load the Language class and data for the given ID via `get_lang_class` and initialize it. The Language class contains the shared vocabulary, tokenization rules and the language-spesific annotation scheme.\n","*   Iterate over the pipeline names and create each component using `create_pipe`, which looks them up in Language.factories\n","*   Add each pipeline component to the pipeline in order, using `add_pipe`.\n","*   Make the model data available to the Language class by calling `from_disk` with the path to the model data directory.  \n","\n","\n","`{`\n","\n","  `\"lang\":\"en\",`\n","\n","  `\"name\":\"core_web_sm\",`\n","\n","  `\"description\":\"Example model for spaCy\",`\n","\n","  `\"pipeline\":[\"tagger\",\"parser\",\"ner\"]`\n","\n","`}`\n","\n","Fundamentally, a spaCy model consists of three components: the weights, i.e. binaty data loaded in from a directory, a pipeline of functions called in order, and language data like the tokenization rules and annotation scheme."],"metadata":{"id":"2GQNLBC4_9GX"}},{"cell_type":"markdown","source":["## Disabling and Modifying Pipeline Components\n","If you don't need a particular component of the pipeline - for example, the tagger or the parser, you can disable loading it. This can sometimes make a big difference and improve loading speed."],"metadata":{"id":"hOI1TfNJGBg4"}},{"cell_type":"code","source":["# Disabling NER (inside nlp.load)\n","nlp = spacy.load(\"en_core_web_sm\", disable=[\"tagger\", \"parser\"])\n","nlp"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aJf8S8ArLjYI","executionInfo":{"status":"ok","timestamp":1741008659642,"user_tz":-60,"elapsed":1083,"user":{"displayName":"Ridvan Yigit","userId":"01752453935051821250"}},"outputId":"4d163bc1-4d5f-41a4-871f-f655635a87a0"},"execution_count":99,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<spacy.lang.en.English at 0x7dab43b9b8d0>"]},"metadata":{},"execution_count":99}]},{"cell_type":"markdown","source":["In some cases, you don't want to load all pipeline components and their weights, because you need them at different points in your application. However, if you only need a Doc object with named entities, there's no need to run all pipeline components on it."],"metadata":{"id":"BWdokm45GtvE"}},{"cell_type":"code","source":["doc = nlp(\"Apple is buying a startup\")\n","\n","for ent in doc.ents:\n","    print(ent.text, ent.label_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VnG2yBMQGm4Y","executionInfo":{"status":"ok","timestamp":1741008659667,"user_tz":-60,"elapsed":13,"user":{"displayName":"Ridvan Yigit","userId":"01752453935051821250"}},"outputId":"cb1e5350-a15c-43cf-df9d-867eb65e4918"},"execution_count":100,"outputs":[{"output_type":"stream","name":"stdout","text":["Apple ORG\n"]}]},{"cell_type":"code","source":["# Disabling NER, Tagger, Parser\n","nlp = spacy.load(\"en_core_web_sm\", disable=[\"tagger\", \"parser\",\"ner\"])\n","doc = nlp(\"Apple is buying a startup\")\n","\n","for ent in doc.ents:\n","    print(ent.text, ent.label_)"],"metadata":{"id":"X5UOTo6oL4Mb","executionInfo":{"status":"ok","timestamp":1741008660614,"user_tz":-60,"elapsed":945,"user":{"displayName":"Ridvan Yigit","userId":"01752453935051821250"}}},"execution_count":101,"outputs":[]},{"cell_type":"code","source":["# 1. Use as a contextmanager\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","with nlp.disable_pipes(\"tagger\", \"parser\"):\n","    doc = nlp(\"I won't be tagged and parsed\")\n","    doc = nlp(\"I will be tagged and parsed\")\n","    print(doc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BLqgSnpEIdCn","executionInfo":{"status":"ok","timestamp":1741008661821,"user_tz":-60,"elapsed":1206,"user":{"displayName":"Ridvan Yigit","userId":"01752453935051821250"}},"outputId":"1531562f-e328-4b4d-ff48-8a4535108e46"},"execution_count":102,"outputs":[{"output_type":"stream","name":"stdout","text":["I will be tagged and parsed\n"]}]},{"cell_type":"code","source":["# 2. Resrtore manually\n","nlp = spacy.load(\"en_core_web_sm\")\n","disablled = nlp.disable_pipes(\"ner\")\n","doc = nlp(\"I won't have named entities\")\n","disablled.restore()\n","print(doc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"miNG6p1RI9V7","executionInfo":{"status":"ok","timestamp":1741008663029,"user_tz":-60,"elapsed":1209,"user":{"displayName":"Ridvan Yigit","userId":"01752453935051821250"}},"outputId":"2f557471-ca3e-4a3d-a877-a640e55cc110"},"execution_count":103,"outputs":[{"output_type":"stream","name":"stdout","text":["I won't have named entities\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ORHTjvHBJOm9","executionInfo":{"status":"ok","timestamp":1741008663031,"user_tz":-60,"elapsed":2,"user":{"displayName":"Ridvan Yigit","userId":"01752453935051821250"}}},"execution_count":103,"outputs":[]}]}